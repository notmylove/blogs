{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tensorflow_3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/notmylove/blogs/blob/master/tensorflow_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "oaUVaIaSI_sX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 使用卷积来提升计算机视觉准确率"
      ]
    },
    {
      "metadata": {
        "id": "AqHsw65dJBI-",
        "colab_type": "code",
        "outputId": "58b58837-aa68-4421-fa54-1de32199bfa8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "mnist = keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "train_images, test_images = train_images/255.0, test_images/255.0\n",
        "model = tf.keras.Sequential([keras.layers.Flatten(),\n",
        "                            keras.layers.Dense(units=128, activation='relu'),\n",
        "                            keras.layers.Dense(units=10, activation='softmax')])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(train_images, train_labels, epochs=5)\n",
        "model.evaluate(test_images, test_labels)\n",
        "classification = model.predict(test_images)\n",
        "print(classification[0], '\\n', test_labels[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 9s 151us/sample - loss: 0.4988 - acc: 0.8243\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 8s 138us/sample - loss: 0.3760 - acc: 0.8659\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 8s 135us/sample - loss: 0.3375 - acc: 0.8772\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 8s 138us/sample - loss: 0.3127 - acc: 0.8853\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 9s 145us/sample - loss: 0.2952 - acc: 0.8912\n",
            "10000/10000 [==============================] - 1s 80us/sample - loss: 0.3475 - acc: 0.8736\n",
            "[1.50778797e-05 6.08186346e-09 6.55398082e-07 3.99823570e-08\n",
            " 1.77626262e-07 8.80285203e-02 5.29756517e-06 1.51415512e-01\n",
            " 1.19555036e-04 7.60415137e-01] \n",
            " 9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DutIxVWNJBfm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**在计算层之前添加卷积层和MaxPooling layer**"
      ]
    },
    {
      "metadata": {
        "id": "zroyDG2ZJBuG",
        "colab_type": "code",
        "outputId": "d5de7a7b-8ce3-4d6d-9d4d-3ddc77f815e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "mnist = keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "train_images=train_images.reshape(60000, 28, 28, 1)\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "train_images, test_images = train_images/255.0, test_images/255.0\n",
        "model = tf.keras.Sequential([keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "                              keras.layers.MaxPooling2D(2, 2),\n",
        "                             keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "                             keras.layers.MaxPooling2D(2, 2),\n",
        "                             keras.layers.Flatten(),\n",
        "                            keras.layers.Dense(units=128, activation='relu'),\n",
        "                            keras.layers.Dense(units=10, activation='softmax')])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "model.fit(train_images, train_labels, epochs=5)\n",
        "model.evaluate(test_images, test_labels)\n",
        "classification = model.predict(test_images)\n",
        "print(classification[0], '\\n', test_labels[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 26, 26, 64)        640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 11, 11, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 128)               204928    \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 243,786\n",
            "Trainable params: 243,786\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 21s 343us/sample - loss: 0.4344 - acc: 0.8410\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 18s 302us/sample - loss: 0.2895 - acc: 0.8935\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 18s 297us/sample - loss: 0.2462 - acc: 0.9088\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 18s 294us/sample - loss: 0.2127 - acc: 0.9219\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 18s 298us/sample - loss: 0.1878 - acc: 0.9295\n",
            "10000/10000 [==============================] - 1s 144us/sample - loss: 0.2551 - acc: 0.9076\n",
            "[4.3628035e-08 1.4799683e-07 4.6029701e-08 1.7194608e-07 8.8480384e-08\n",
            " 1.2560084e-04 6.3423961e-08 1.6434671e-04 1.9785919e-06 9.9970740e-01] \n",
            " 9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XQItA7EnJB2m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**加了卷积层和maxpooling layer层准确率确实有显著提高**，因为通常它的功能可以将一些edge特征突出显示，将一个项目分为另一个项目，然后所需的信息量就更少了......因为您只需要对突出显示的特征进行训练。\n",
        "\n",
        "这里训练数据与测试数据较之前的不同，数据的形状需要reshape。 那是因为第一个卷积需要一个包含所有内容的单张量，所以我们需要一个60000$*$28$*$28$*$1的4D列表，而不是列表中的60,000个28$*$28$*$1项目，而且测试数据也是如此。 如果不这样做，训练时会出现错误，因为“卷积”无法识别形状。"
      ]
    },
    {
      "metadata": {
        "id": "ERhTmbT_JB9Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_images=train_images.reshape(60000, 28, 28, 1)\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LsNfsfKAJCFW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ">Next is to define your model. Now instead of the input layer at the top, you're going to add a Convolution. The parameters are:\n",
        "\n",
        ">1. The number of convolutions you want to generate. Purely arbitrary, but good to start with something in the order of 32\n",
        ">2. The size of the Convolution, in this case a 3x3 grid\n",
        "> 3. The activation function to use -- in this case we'll use relu, which you might recall is the equivalent of returning x when x>0, else returning 0\n",
        ">4. In the first layer, the shape of the input data."
      ]
    },
    {
      "metadata": {
        "id": "BUXbtbxgBlbT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**配合卷积层一起使用的是maxpooling layer，目的是为了压缩图像，同时也可以保持由卷积层突出显示的特征的内容**，通过为MaxPooling指定一个（2, 2）的数组，效果相当于对图像的大小进行四分之一。创建了一个2x2的像素阵列，然后选择最大的像素，从而将4个像素变为1.它在整个图像中重复这个，并且这样做可以将水平与垂直像素数减半，有效地将图像减少25％。"
      ]
    },
    {
      "metadata": {
        "id": "qvTAnqnpFr9t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Visualizing the Convolutions and Pooling"
      ]
    },
    {
      "metadata": {
        "id": "zdIsQmLIFyVM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**下面这段代码将以图形的形式为我们展示卷积**，print(test_labels[:100])打印出前100个测试集的标签，其中index 0, index 23 and index 28 的值都为9，表示属于同一类（鞋），让我们来看看在每个运行卷积的结果，可以看到它们之间出现的共同特征。"
      ]
    },
    {
      "metadata": {
        "id": "vXOsz6Sz9_1J",
        "colab_type": "code",
        "outputId": "a1efa738-13be-4230-adfa-1748672465a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "print(test_labels[:100])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[9 2 1 1 6 1 4 6 5 7 4 5 7 3 4 1 2 4 8 0 2 5 7 9 1 4 6 0 9 3 8 8 3 3 8 0 7\n",
            " 5 7 9 6 1 3 7 6 7 2 1 2 2 4 4 5 8 2 2 8 4 8 0 7 7 8 5 1 1 2 3 9 8 7 0 2 6\n",
            " 2 3 1 2 8 4 1 8 5 9 5 0 3 2 0 6 5 3 6 7 1 8 0 1 4 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CjqdJ9edTTGU",
        "colab_type": "code",
        "outputId": "4a4198b2-dcd9-41dc-fc2d-5a1d62b8ad46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "FIRST_IMAGE=0\n",
        "SECOND_IMAGE=23\n",
        "THIRD_IMAGE=28\n",
        "CONVOLUTION_NUMBER = 1\n",
        "\n",
        "layer_outputs = [layer.output for layer in model.layers]\n",
        "activation_model = tf.keras.Model(inputs = model.input, outputs = layer_outputs)\n",
        "print(model.layers, '\\n', model.output)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f160a21b128>, <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f160a321fd0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f160a328048>, <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f160a328160>, <tensorflow.python.keras.layers.core.Flatten object at 0x7f160a328240>, <tensorflow.python.keras.layers.core.Dense object at 0x7f160a3282b0>, <tensorflow.python.keras.layers.core.Dense object at 0x7f160a328400>] \n",
            " Tensor(\"dense_9/Softmax:0\", shape=(?, 10), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gQDdl1aKWPp_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**model.output**得到的是最后的输出张量，而我们是要展现卷积层后图形的变化，因此要**layer_outputs = [layer.output for layer in model.layers]**，这里得到的就是每一层的输出列表"
      ]
    },
    {
      "metadata": {
        "id": "I1M1Zj3QQGP4",
        "colab_type": "code",
        "outputId": "6976f8c4-5705-4f25-e25e-f3db2dd5a518",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "figure, ax = plt.subplots(3,4)\n",
        "\n",
        "FIRST_IMAGE=0\n",
        "SECOND_IMAGE=23\n",
        "THIRD_IMAGE=28\n",
        "CONVOLUTION_NUMBER = 1\n",
        "\n",
        "layer_outputs = [layer.output for layer in model.layers]\n",
        "activation_model = tf.keras.Model(inputs = model.input, outputs = layer_outputs)\n",
        "for x in range(0,4):\n",
        "  f1 = activation_model.predict(test_images[FIRST_IMAGE].reshape(1, 28, 28, 1))[x]\n",
        "  ax[0,x].imshow(f1[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
        "  ax[0,x].grid(False)\n",
        "  f2 = activation_model.predict(test_images[SECOND_IMAGE].reshape(1, 28, 28, 1))[x]\n",
        "  ax[1,x].imshow(f2[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
        "  ax[1,x].grid(False)\n",
        "  f3 = activation_model.predict(test_images[THIRD_IMAGE].reshape(1, 28, 28, 1))[x]\n",
        "  ax[2,x].imshow(f3[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
        "  ax[2,x].grid(False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdUAAAFMCAYAAACd0CZ8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x396 with 12 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "9JbpKBV7aBrn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 改变产生卷积的数目"
      ]
    },
    {
      "metadata": {
        "id": "WvOq82rPaTy1",
        "colab_type": "code",
        "outputId": "033c4ef1-30de-426f-96e3-b1124fc74bb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "mnist = keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "train_images=train_images.reshape(60000, 28, 28, 1)\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "train_images, test_images = train_images/255.0, test_images/255.0\n",
        "model = tf.keras.Sequential([keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "                              keras.layers.MaxPooling2D(2, 2),\n",
        "                             keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "                             keras.layers.MaxPooling2D(2, 2),\n",
        "                             keras.layers.Flatten(),\n",
        "                            keras.layers.Dense(units=128, activation='relu'),\n",
        "                            keras.layers.Dense(units=10, activation='softmax')])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "model.fit(train_images, train_labels, epochs=5)\n",
        "model.evaluate(test_images, test_labels)\n",
        "classification = model.predict(test_images)\n",
        "print(classification[0], '\\n', test_labels[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_8 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 11, 11, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 5, 5, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 800)               0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 128)               102528    \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 113,386\n",
            "Trainable params: 113,386\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 16s 264us/sample - loss: 0.4645 - acc: 0.8314\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 16s 269us/sample - loss: 0.3176 - acc: 0.8836\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 16s 267us/sample - loss: 0.2715 - acc: 0.8998\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 16s 262us/sample - loss: 0.2410 - acc: 0.9111\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 16s 262us/sample - loss: 0.2174 - acc: 0.9181\n",
            "10000/10000 [==============================] - 1s 131us/sample - loss: 0.2557 - acc: 0.9063\n",
            "[1.1727572e-06 4.9704543e-08 2.8948131e-07 2.1731376e-08 1.6070712e-06\n",
            " 3.9628549e-03 9.7691697e-08 7.9013890e-04 1.1266534e-06 9.9524271e-01] \n",
            " 9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "C8EEEBHea0fE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 减少卷积层和MaxPooling layer"
      ]
    },
    {
      "metadata": {
        "id": "MfzVsmZQa-Gt",
        "colab_type": "code",
        "outputId": "fe842255-6808-4adb-8274-e89b9dd22a11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 755
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "mnist = keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "train_images=train_images.reshape(60000, 28, 28, 1)\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "train_images, test_images = train_images/255.0, test_images/255.0\n",
        "model = tf.keras.Sequential([keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "                              keras.layers.MaxPooling2D(2, 2),\n",
        "                             keras.layers.Flatten(),\n",
        "                            keras.layers.Dense(units=128, activation='relu'),\n",
        "                            keras.layers.Dense(units=10, activation='softmax')])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "model.fit(train_images, train_labels, epochs=10)\n",
        "model.evaluate(test_images, test_labels)\n",
        "classification = model.predict(test_images)\n",
        "print(classification[0], '\\n', test_labels[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_14 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_10 (Flatten)         (None, 5408)              0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 128)               692352    \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 693,962\n",
            "Trainable params: 693,962\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 15s 248us/sample - loss: 0.3838 - acc: 0.8632\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 14s 239us/sample - loss: 0.2623 - acc: 0.9057\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 14s 232us/sample - loss: 0.2163 - acc: 0.9206\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 13s 219us/sample - loss: 0.1830 - acc: 0.9329\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 13s 216us/sample - loss: 0.1565 - acc: 0.9419\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 12s 207us/sample - loss: 0.1323 - acc: 0.9508\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 12s 194us/sample - loss: 0.1106 - acc: 0.9588\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 11s 189us/sample - loss: 0.0937 - acc: 0.9658\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 11s 190us/sample - loss: 0.0790 - acc: 0.9717\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 11s 191us/sample - loss: 0.0651 - acc: 0.9762\n",
            "10000/10000 [==============================] - 1s 90us/sample - loss: 0.3502 - acc: 0.9077\n",
            "[3.4110766e-11 2.6937274e-13 3.2053973e-09 2.4932273e-15 1.3277197e-14\n",
            " 1.2320863e-09 5.2675876e-13 1.3536474e-08 1.3124843e-10 1.0000000e+00] \n",
            " 9\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}